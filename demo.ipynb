{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bb5854",
   "metadata": {},
   "source": [
    "# üîç Vector Database Demo with LSH-based Clustering\n",
    "\n",
    "This notebook demonstrates a lightweight vector database implementation for semantic search that combines:\n",
    "\n",
    "#### ‚ú® Key Features\n",
    "- **üß© Flexible Architecture**: Uses abstract base classes to allow swapping embedding models without changing search logic.\n",
    "- **üßÆ LSH-based Clustering**: Implements Locality Sensitive Hashing (LSH) to cluster semantically similar documents.\n",
    "- **üöÄ Optimized Search Strategy**: Uses a two-phase search approach:\n",
    "  1. First searches within the query's LSH cluster.\n",
    "  2. Intelligently explores neighboring clusters until reaching diminishing returns.\n",
    "- **üõë Early Termination**: Stops searching additional clusters after N consecutive failures to find closer documents.\n",
    "\n",
    "The demo shows how to setup the database, encode documents using Azure OpenAI embeddings, and perform efficient semantic search queries using the LSH-accelerated approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053bf02a",
   "metadata": {},
   "source": [
    "## (1) SQLite Database Setup\n",
    "\n",
    "Run the script db_setup.py to automatically create the required SQLite database file.\n",
    "```\n",
    "usage: db_setup.py [-h] -t TAG\n",
    "\n",
    "Setup the vector database. Creates necessary tables (Documents, Neighbors).\n",
    "\n",
    "options:\n",
    "  -h, --help         show this help message and exit\n",
    "  -t TAG, --tag TAG  Required: Tag or name for the database file (e.g., 'my_vec_library.db')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4839c",
   "metadata": {},
   "source": [
    "## (2) Document pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0d8e39",
   "metadata": {},
   "source": [
    "(2.1) Create the embedding model by subclassing the EmbeddingModel abstraction. In this example implementation we'll use an OpenAI model in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from abstract.base import EmbeddingModel, VectorDatabase\n",
    "from openai import AzureOpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "API_KEY = \"<your_api_key>\"\n",
    "ENDPOINT = \"<your_endpoint>\"\n",
    "DEPLOYMENT = \"text-embedding-3-large\"\n",
    "SQLITE_DB_PATH = \"<your_db_file_path>.db\"\n",
    "\n",
    "\n",
    "class AzureOpenAIEmbeddingModel(EmbeddingModel):\n",
    "    def __init__(self, api_key: str, endpoint: str, deployment: str, batch_size: int = 32):\n",
    "        self.api_key = api_key\n",
    "        self.endpoint = endpoint\n",
    "        self.deployment = deployment\n",
    "        self.batch_size = batch_size\n",
    "        self.client = AzureOpenAI(\n",
    "            api_version=\"2024-12-01-preview\",\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def get_embedding_dimension() -> int:\n",
    "        return 3072\n",
    "\n",
    "    def embed_documents(self, documents: list[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Given a list of documents, return their embeddings as a numpy array.\n",
    "        Documents are processed in batches to avoid API throttling.\n",
    "        Uses binary search to find the largest working batch size.\n",
    "        \"\"\"\n",
    "        all_embeddings = []\n",
    "        n = len(documents)\n",
    "        i = 0\n",
    "        max_batch = self.batch_size\n",
    "        min_batch = 1\n",
    "        while i < n:\n",
    "            batch_size = max_batch\n",
    "            success = False\n",
    "            while batch_size >= min_batch and not success:\n",
    "                batch = documents[i:i+batch_size]\n",
    "                try:\n",
    "                    response = self.client.embeddings.create(\n",
    "                        input=batch,\n",
    "                        model=self.deployment\n",
    "                    )\n",
    "                    all_embeddings.extend([item.embedding for item in response.data])\n",
    "                    i += batch_size\n",
    "                    # Try to increase batch size for next round\n",
    "                    if batch_size < max_batch:\n",
    "                        batch_size = min(batch_size * 2, max_batch)\n",
    "                    success = True\n",
    "                except Exception as e:\n",
    "                    # On error, halve batch size and retry\n",
    "                    if batch_size == 1:\n",
    "                        # If even batch size 1 fails, raise\n",
    "                        raise\n",
    "                    batch_size = batch_size // 2\n",
    "                    time.sleep(1)  # brief backoff\n",
    "        return np.array(all_embeddings)\n",
    "\n",
    "    def distance(self, emb1: np.ndarray, emb2: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Cosine distance for normalized embeddings: 1 - dot(emb1, emb2)\n",
    "        Lower is more similar.\n",
    "        \"\"\"\n",
    "        return 1.0 - float(np.dot(emb1, emb2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1bae70",
   "metadata": {},
   "source": [
    "(2.2) Implement VectorDatabase using our AzureOpenAI model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dce47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDatabaseAzure(VectorDatabase):\n",
    "    def get_embedding_model(self):\n",
    "        return AzureOpenAIEmbeddingModel(\n",
    "            api_key=API_KEY,\n",
    "            endpoint=ENDPOINT,\n",
    "            deployment=DEPLOYMENT,\n",
    "        )\n",
    "    \n",
    "vdb = VectorDatabaseAzure(SQLITE_DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b46cd63",
   "metadata": {},
   "source": [
    " (2.3) Run the documents' text through the model and store the embeddings in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6626d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 87/87 [10:12<00:00,  7.04s/it]\n"
     ]
    }
   ],
   "source": [
    "# test.tgt is from https://huggingface.co/datasets/alexfabbri/multi_news/tree/main/data\n",
    "with open(\"test.tgt\", \"r\") as file:\n",
    "    lines = file.read().splitlines()\n",
    "\n",
    "batch_size = 64\n",
    "for i in tqdm(range(0, len(lines), batch_size)):\n",
    "    vdb.add_documents(lines[i:i + batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d7498",
   "metadata": {},
   "source": [
    "# (3) Demo - using the vector DB to search for documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d66530a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs searched: 2904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.7283551096916199,\n",
       "  '‚Äì You probably can already identify the contents of most of your photos, but this is still fun. A new website from Stephen Wolfram, whom you may know from the search tool WolframAlpha, lets you drag and drop any photo; it will then in theory identify what\\'s in it. Right now, ImageIdentify manages some impressive feats, the Verge reports: For instance, it was able to tell that a picture of a cow was a black angus. On the other hand, it thought a cupcake was a bottle cap. The Wolfram Language team is happy to acknowledge the mistakes. In a blog post, Wolfram notes that \"somehow the errors seemed very understandable, and in a sense very human. It seemed as if what ImageIdentify was doing was successfully capturing some of the essence of the human process of identifying images.\" In the meantime, it does have some practical uses: At PC World, Jared Newman writes that \"using the site, I was able to figure the breed of dog that kept following my wife and I around on our honeymoon (miniature pinscher) and the exact type of flower from a hike in Los Angeles (larkspur).\" And we can expect ImageIdentify to get better at its job, since it keeps copies of the images you post and learns from them; its abilities come from the study of tens of millions of pictures, Wolfram says. You can also tell the site whether its analysis was correct. It\\'s not the only such system, the Verge notes, pointing to efforts like Google Goggles. (What would it say about this smiley face in space?)'),\n",
       " (0.7364537119865417,\n",
       "  '‚Äì The automated photo-tagging on the Google Photos app introduced in May isn\\'t perfect, Google admits. Sometimes it gives a photo a wrong or irrelevant tag‚Äîand, on at least one occasion, an extremely offensive one. The company had some groveling to do after the app labeled a photo of two black people as \"gorillas,\" the Guardian reports. The man in the photo, software developer Jacky Alcine, complained to Google, where exec Yonatan Zunger told him the mistake was \"100% not OK\" and \"high on my list of bugs you \\'never\\' want to see happen,\" the BBC reports. He thanked him for helping Google fix the problem. \"We\\'re appalled and genuinely sorry that this happened,\" a Google spokeswoman tells the BBC. \"We are taking immediate action to prevent this type of result from appearing. There is still clearly a lot of work to do with automatic image labeling, and we\\'re looking at how we can prevent these types of mistakes from happening in the future.\" Algorithms caused similar problems at Flickr a few months ago, where some pictures of people, both black and white, were labeled \"apes\" or \"animals,\" and a picture of the Dachau concentration camp was labeled \"jungle gym,\" CNET notes. (Apple Watch gets confused by tattoos.)'),\n",
       " (0.7413123846054077,\n",
       "  '‚Äì Scientists at UC Berkeley have made a major advancement in the field of mind reading, reconstructing YouTube videos based on brain scans from people who‚Äôd seen them. Researchers would put subjects into an MRI machine and track their brain activity as they viewed videos. Once they‚Äôd build a model of how a subject‚Äôs mind processed the video, ‚Äúwe could read brain activity for that subject and run it backward ‚Ä¶ to try to uncover what the viewer saw,‚Äù one study coauthor tells ABC News. Using the scans they were then able to reproduce the videos‚Äîthough they‚Äôre blurry. ‚ÄúThis is a major leap,‚Äù the co-author says. He thinks the technique could eventually be used to reconstruct dreams or memories, if it turns out the brain processes those things similarly to how it processes movies. ‚ÄúIt‚Äôs our next line of research.‚Äù (More details on how the experiment worked, along with a video, at PC Magazine.)'),\n",
       " (0.7555873394012451,\n",
       "  '‚Äì Uber looks like it\\'s trying to get in on the self-driving cars business, officially announcing this week that it\\'s partnering with Carnegie Mellon University (home to the Mars Rover) to build the Uber Advanced Technologies Center in Pittsburgh‚Äîin other words, \"kickstart autonomous taxi fleet development,\" inside sources tell TechCrunch. And while Uber wouldn\\'t say as much, sources allege that the company is hiring more than 50 senior scientists from the university, as well as an affiliated robotics research center; Uber does say the partnership will focus on \"mapping and vehicle safety and autonomy technology.\" It\\'s not the first time Uber CEO Travis Kalanick has talked about turning real drivers into robotic ones. Meanwhile Google, which Grist reports has thus far played nice with Uber by sharing Google Maps and investing $258 million in its app, might be ending that streak. Google appears to be creating its own ride-hailing app, reports Bloomberg Business, and is already well ahead of Uber when it comes to autonomous vehicles. Curiously, David Drummond, Google\\'s chief legal officer, is so far still maintaining a spot on Uber‚Äôs board, even though the two companies appear to be on the verge of becoming competitors. (Uber\\'s legal troubles continue to mount around the world.)'),\n",
       " (0.7560957372188568,\n",
       "  '‚Äì Researchers from London\\'s Imperial College think they\\'ve found two networks of genes, possibly controlled by a master system, that control cognitive functions‚Äîa find that may allow them to modify human intelligence down the line, the Guardian reports. In a study published in Nature Neuroscience, scientists say these M1 and M3 clusters control cognitive functions such as memory, attention, and reasoning, per the Daily Express. \"Traits such as intelligence are governed by large groups of [genes] working together‚Äîlike a football team made up of players in different [positions],\" study co-author Dr. Michael Johnson says, per the Guardian. By figuring out how these \"players\" work together, scientists could perhaps boost cognitive abilities by simply flicking the equivalent of a master switch. And based on other findings in the study linking mutations of those same genes to cognitive impairments, research in this area may be lead to treatment of cognitive issues that accompany neurodevelopmental diseases such as epilepsy, Dr. Johnson notes, per the Guardian. Researchers analyzed \"huge sets of data\" taken from samples of mouse and human brains, the paper notes, as well as info from a previous health study and genetic data from volunteers (both healthy ones and those with autism and other intellectual disabilities) who took IQ tests. Not only did they find evidence for the disparate gene networks‚Äîthey also found that the same genes that apparently contribute to the intelligence of healthy subjects damaged cognitive abilities if they were mutated. \"Eventually we hope that this sort of analysis will provide new insights into better treatments for neurodevelopmental disease ‚Ä¶ and ameliorate or treat the cognitive impairments associated with these devastating diseases,\" Johnson says. Not everyone is thrilled with the idea of flipping a switch to play around with intelligence functioning. \"Genetics is the science of inheritance, not pre-determinism, and there is no substitute for hard work and application,\" a University of Kent genetics professor tells the Express. (Predict your kid\\'s intelligence‚Äîwith a raisin.)')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"something about machine learning\"\n",
    "# Use the Vector DB to fetch documents\n",
    "docs = vdb.get_closest_documents(query, 5, search_all=False)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddcdd6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs searched: 5622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.7283551096916199,\n",
       "  '‚Äì You probably can already identify the contents of most of your photos, but this is still fun. A new website from Stephen Wolfram, whom you may know from the search tool WolframAlpha, lets you drag and drop any photo; it will then in theory identify what\\'s in it. Right now, ImageIdentify manages some impressive feats, the Verge reports: For instance, it was able to tell that a picture of a cow was a black angus. On the other hand, it thought a cupcake was a bottle cap. The Wolfram Language team is happy to acknowledge the mistakes. In a blog post, Wolfram notes that \"somehow the errors seemed very understandable, and in a sense very human. It seemed as if what ImageIdentify was doing was successfully capturing some of the essence of the human process of identifying images.\" In the meantime, it does have some practical uses: At PC World, Jared Newman writes that \"using the site, I was able to figure the breed of dog that kept following my wife and I around on our honeymoon (miniature pinscher) and the exact type of flower from a hike in Los Angeles (larkspur).\" And we can expect ImageIdentify to get better at its job, since it keeps copies of the images you post and learns from them; its abilities come from the study of tens of millions of pictures, Wolfram says. You can also tell the site whether its analysis was correct. It\\'s not the only such system, the Verge notes, pointing to efforts like Google Goggles. (What would it say about this smiley face in space?)'),\n",
       " (0.7364537119865417,\n",
       "  '‚Äì The automated photo-tagging on the Google Photos app introduced in May isn\\'t perfect, Google admits. Sometimes it gives a photo a wrong or irrelevant tag‚Äîand, on at least one occasion, an extremely offensive one. The company had some groveling to do after the app labeled a photo of two black people as \"gorillas,\" the Guardian reports. The man in the photo, software developer Jacky Alcine, complained to Google, where exec Yonatan Zunger told him the mistake was \"100% not OK\" and \"high on my list of bugs you \\'never\\' want to see happen,\" the BBC reports. He thanked him for helping Google fix the problem. \"We\\'re appalled and genuinely sorry that this happened,\" a Google spokeswoman tells the BBC. \"We are taking immediate action to prevent this type of result from appearing. There is still clearly a lot of work to do with automatic image labeling, and we\\'re looking at how we can prevent these types of mistakes from happening in the future.\" Algorithms caused similar problems at Flickr a few months ago, where some pictures of people, both black and white, were labeled \"apes\" or \"animals,\" and a picture of the Dachau concentration camp was labeled \"jungle gym,\" CNET notes. (Apple Watch gets confused by tattoos.)'),\n",
       " (0.7413123846054077,\n",
       "  '‚Äì Scientists at UC Berkeley have made a major advancement in the field of mind reading, reconstructing YouTube videos based on brain scans from people who‚Äôd seen them. Researchers would put subjects into an MRI machine and track their brain activity as they viewed videos. Once they‚Äôd build a model of how a subject‚Äôs mind processed the video, ‚Äúwe could read brain activity for that subject and run it backward ‚Ä¶ to try to uncover what the viewer saw,‚Äù one study coauthor tells ABC News. Using the scans they were then able to reproduce the videos‚Äîthough they‚Äôre blurry. ‚ÄúThis is a major leap,‚Äù the co-author says. He thinks the technique could eventually be used to reconstruct dreams or memories, if it turns out the brain processes those things similarly to how it processes movies. ‚ÄúIt‚Äôs our next line of research.‚Äù (More details on how the experiment worked, along with a video, at PC Magazine.)'),\n",
       " (0.7555873394012451,\n",
       "  '‚Äì Uber looks like it\\'s trying to get in on the self-driving cars business, officially announcing this week that it\\'s partnering with Carnegie Mellon University (home to the Mars Rover) to build the Uber Advanced Technologies Center in Pittsburgh‚Äîin other words, \"kickstart autonomous taxi fleet development,\" inside sources tell TechCrunch. And while Uber wouldn\\'t say as much, sources allege that the company is hiring more than 50 senior scientists from the university, as well as an affiliated robotics research center; Uber does say the partnership will focus on \"mapping and vehicle safety and autonomy technology.\" It\\'s not the first time Uber CEO Travis Kalanick has talked about turning real drivers into robotic ones. Meanwhile Google, which Grist reports has thus far played nice with Uber by sharing Google Maps and investing $258 million in its app, might be ending that streak. Google appears to be creating its own ride-hailing app, reports Bloomberg Business, and is already well ahead of Uber when it comes to autonomous vehicles. Curiously, David Drummond, Google\\'s chief legal officer, is so far still maintaining a spot on Uber‚Äôs board, even though the two companies appear to be on the verge of becoming competitors. (Uber\\'s legal troubles continue to mount around the world.)'),\n",
       " (0.7560957372188568,\n",
       "  '‚Äì Researchers from London\\'s Imperial College think they\\'ve found two networks of genes, possibly controlled by a master system, that control cognitive functions‚Äîa find that may allow them to modify human intelligence down the line, the Guardian reports. In a study published in Nature Neuroscience, scientists say these M1 and M3 clusters control cognitive functions such as memory, attention, and reasoning, per the Daily Express. \"Traits such as intelligence are governed by large groups of [genes] working together‚Äîlike a football team made up of players in different [positions],\" study co-author Dr. Michael Johnson says, per the Guardian. By figuring out how these \"players\" work together, scientists could perhaps boost cognitive abilities by simply flicking the equivalent of a master switch. And based on other findings in the study linking mutations of those same genes to cognitive impairments, research in this area may be lead to treatment of cognitive issues that accompany neurodevelopmental diseases such as epilepsy, Dr. Johnson notes, per the Guardian. Researchers analyzed \"huge sets of data\" taken from samples of mouse and human brains, the paper notes, as well as info from a previous health study and genetic data from volunteers (both healthy ones and those with autism and other intellectual disabilities) who took IQ tests. Not only did they find evidence for the disparate gene networks‚Äîthey also found that the same genes that apparently contribute to the intelligence of healthy subjects damaged cognitive abilities if they were mutated. \"Eventually we hope that this sort of analysis will provide new insights into better treatments for neurodevelopmental disease ‚Ä¶ and ameliorate or treat the cognitive impairments associated with these devastating diseases,\" Johnson says. Not everyone is thrilled with the idea of flipping a switch to play around with intelligence functioning. \"Genetics is the science of inheritance, not pre-determinism, and there is no substitute for hard work and application,\" a University of Kent genetics professor tells the Express. (Predict your kid\\'s intelligence‚Äîwith a raisin.)')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = vdb.get_closest_documents(query, 5, search_all=True)\n",
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
